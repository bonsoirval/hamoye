{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6163cf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "technologies   = ({\n",
    "    'Courses':[\"Spark\",\"PySpark\",\"Hadoop\",\"Python\",\"Pandas\",\"Hadoop\",\"Spark\",\"Python\"],\n",
    "    'Fee' :[22000,25000,23000,24000,26000,25000,25000,22000],\n",
    "    'Duration':['30days','50days','55days','40days','60days','35days','55days','50days'],\n",
    "    'Discount':[1000,2300,1000,1200,2500,1300,1400,1600]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd48d22c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Courses    Fee Duration  Discount\n",
      "1    Spark  22000   30days      1000\n",
      "2  PySpark  25000   50days      2300\n",
      "3   Hadoop  23000   55days      1000\n",
      "4   Python  24000   40days      1200\n",
      "5   Pandas  26000   60days      2500\n",
      "6   Hadoop  25000   35days      1300\n",
      "7    Spark  25000   55days      1400\n",
      "8   Python  22000   50days      1600\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(technologies, columns = ['Courses', 'Fee', 'Duration', 'Discount'], index = [1,2,3,4,5,6,7,8])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee25ba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee  Discount\n",
      "Courses                 \n",
      "Hadoop   48000      2300\n",
      "Pandas   26000      2500\n",
      "PySpark  25000      2300\n",
      "Python   46000      2800\n",
      "Spark    47000      2400\n"
     ]
    }
   ],
   "source": [
    "df2 = df.groupby('Courses').sum()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a26d36",
   "metadata": {},
   "source": [
    "You can also explicitly specify on which column you wanted to do a sum operation. The below\n",
    "example applies the sum on the Fee column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d170040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses\n",
      "Hadoop     48000\n",
      "Pandas     26000\n",
      "PySpark    25000\n",
      "Python     46000\n",
      "Spark      47000\n",
      "Name: Fee, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Use groupby() and compute sum on specific column\n",
    "df2 = df.groupby('Courses')['Fee'].sum()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b62441f",
   "metadata": {},
   "source": [
    "You can also send a list of columns you wanted group to groupby() method, using this you \n",
    "can apply a group by on multiple columns and calculate a sum over each combination group.\n",
    "For example, df.groupby(['Course', 'Duration']).['Fee'].sum() does group on Courses and \n",
    "Duration column and finally calculates the sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5478fee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Courses  Duration\n",
      "Hadoop   35days      25000\n",
      "         55days      23000\n",
      "Pandas   60days      26000\n",
      "PySpark  50days      25000\n",
      "Python   40days      24000\n",
      "         50days      22000\n",
      "Spark    30days      22000\n",
      "         55days      25000\n",
      "Name: Fee, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df2 = df.groupby(['Courses', 'Duration',])['Fee'].sum()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93be9ac",
   "metadata": {},
   "source": [
    "Groupby and Get Sum and Count\n",
    "You can also use df.groupby('Courses')['Fee'].agg(['sum', 'count']) to get both sum() and \n",
    "count() on groupby(), you dont want to reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd2a4142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           sum  count\n",
      "Courses              \n",
      "Hadoop   48000      2\n",
      "Pandas   26000      1\n",
      "PySpark  25000      1\n",
      "Python   46000      2\n",
      "Spark    47000      2\n"
     ]
    }
   ],
   "source": [
    "# Groupby and get sum() and count()\n",
    "df2 = df.groupby('Courses')['Fee'].agg(['sum', 'count'])\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7449e216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee      \n",
      "           sum count\n",
      "Courses             \n",
      "Hadoop   48000     2\n",
      "Pandas   26000     1\n",
      "PySpark  25000     1\n",
      "Python   46000     2\n",
      "Spark    47000     2\n"
     ]
    }
   ],
   "source": [
    "# Pandas groupby get sum() and count()\n",
    "df2 = df.groupby('Courses').agg({'Fee':['sum', 'count']})\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a775425a",
   "metadata": {},
   "source": [
    "Sort Descending order Group By Keys\n",
    "By default groupby() method sorts results by group key hence it will take additional time, \n",
    "if you have a performance issue and donâ€™t want to sort the group by the result, you can turn this off by using the sort=False param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b1dee44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee  Discount\n",
      "Courses                 \n",
      "Spark    47000      2400\n",
      "PySpark  25000      2300\n",
      "Hadoop   48000      2300\n",
      "Python   46000      2800\n",
      "Pandas   26000      2500\n"
     ]
    }
   ],
   "source": [
    "# Remove sorting on grouped results\n",
    "df2 = df.groupby(['Courses'], sort=False).sum()\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de247d15",
   "metadata": {},
   "source": [
    "# If you wanted to sort key descending order, use below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "953c7682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Fee  Discount\n",
      "Courses                 \n",
      "Spark    47000      2400\n",
      "PySpark  25000      2300\n",
      "Hadoop   48000      2300\n",
      "Python   46000      2800\n",
      "Pandas   26000      2500\n"
     ]
    }
   ],
   "source": [
    "# Sorting group keys on descending order\n",
    "groupedDF = df.groupby('Courses', sort=False).sum()\n",
    "sortedDF = groupedDF.sort_values('Courses', ascending=False)\n",
    "print(groupedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d687ab4e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
